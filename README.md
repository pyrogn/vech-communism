# Вечерний коммунизм

## Весь код в "for github.ipynb"

### Проблема
1. Есть категория сайта b17 со всеми отзывами. (примерно 320 страниц, на каждой по 25, тоже примерно).
2. На каждого человека выделяется по 2 страницы отзывов. Но при этом надо брать именно психологов, а потом скачивать все отзывы этих психологов.
3. Помимо отзывов надо добывать информацию о психологе в профиле (это вручную в основном).
4. Много. Индивидуальная таблица получается длиной в 2500 строк примерно (вообще грубо примерно, не считал калькулятором).
5. Глупо делать вручную и в одиночку (так как психологи сильно повторяются).

### Решение
1. Запарсить все id психологов.
2. Запарсить все отзывы этих психологов.
3. Найти команду.
4. Распределить равномерно заполнение доп. информации.
5. После чего для каждого человека генерировать личную таблицу.

### Всякие штучки
1. Парадокс наблюдателя (интересно). Так как мы выбираем психологов по отзывам, а не случайно по списку психологов.
2. Экономия времени с 10 до 2 часов (примерно). Но сам программист потратил от 10 часов.
3. Итоговая таблица получилась длиной в 9 тысяч строк. А каждая индивидуальная примерно в 2.5 тысяч строк. Вдумайтесь, сколько дубликатов мы нагенерировали.
4. Задание непроработанное, так как при добавлении новых отзывов все отзывы (и психологи) сдвигаются.


### В папке scrap_files лежат данные.

